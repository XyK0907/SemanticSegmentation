# ZMO

## pipeline


**Skin Segmentation --> Skin Color Extractation --> Color Transfer --> Skin + Background Integration**

拿到这个题目，由于网络的网速限制以及不稳定，无法获得大量的训练数据集，因此不能进行GAN或者普通网络的训练。所以我只能考虑从利用普通机器学习或者视觉库，或者利用预训练的网络来完成这项任务。

要只针对皮肤的颜色进行改变而不改变其它部位的颜色，那么最好是能够对皮肤进行单独的处理，而不是直接针对整张图片进行颜色的改变。那么找到皮肤并将皮肤分割出来，是最直观的想法。

### Skin Segmentation

通过查阅资料，我发现能够直接利用OpenCV进行皮肤的检测及分割。
比如 [**Skin Detection: A Step-by-Step Example using Python and OpenCV**](https://www.pyimagesearch.com/2014/08/18/skin-detection-step-step-example-using-python-opencv/) 、[**6种肤色检测方法的原理及实现**](https://www.guyuehome.com/34252)或是 [**SkinDetection**](https://github.com/CHEREF-Mehdi/SkinDetection)。
其原理主要是利用在不同颜色空间内，正常皮肤的颜色会有一个上下阈值。在此阈值内的颜色像素则被认为是皮肤。这种方法简单轻便能够迅速获得大片的皮肤面积。但是缺点是不够精确，比如在不同的光照条件下，在HSV颜色空间内，对于皮肤面积的判定影响很大。

还有一个想法就是通过已经预训练过的网络获得Skin segmentation。https://github.com/WillBrennan/SemanticSegmentation 提供了能够直接进行Skin Segmentation 的网络。此网络是由150张COCO数据集中的图片训练的结果。训练的图片量不大，但效果不错。我尝试了OpenCV和此预训练的网络两种方法,发现预训练网络效果更好。尽管还是有不精确的地方存在，但要是用更多的数据集进行训练过的话，效果应该会更好。所以我选择了这个预训练过的网络对皮肤进行分割。举例来说，一下四张图片，后两张分割效果较好，前两张有瑕疵。

![001](https://github.com/XyK0907/SemanticSegmentation/blob/master/mask_skin_001.jpg?raw=true)
![003](https://github.com/XyK0907/SemanticSegmentation/blob/master/mask_skin_003.jpg?raw=true)
![004](https://github.com/XyK0907/SemanticSegmentation/blob/master/mask_skin_004.jpg?raw=true)
![005](https://github.com/XyK0907/SemanticSegmentation/blob/master/mask_skin_005.jpg?raw=true)

###  Color Transfer
关于颜色迁移，我选择了[Rheinhard经典颜色迁移算法](https://www.cs.tau.ac.il/~turkel/imagepapers/ColorTransfer.pdf)。此算法能够计算原图片和目标图片的均值和标准差。那么，可以选择若干张不同肤色的模特作为原图片，经过Skin Segmentation 后，对获得的segmentation图片进行肤色的提取，并将提取的肤色转移到目标图片上去。
比如若是以下小姐姐的肤色作为源肤色，
![00](https://github.com/XyK0907/SemanticSegmentation/blob/master/00.jpg?raw=true)

则转换后的图片如下所示，可以看出由于1号图片皮肤检测时并没有检测要腰间的皮肤，所以腰间皮肤没能成功转换颜色；其它肤色均成功的转换了，但由于4、5、6号图片原本肤色较黑，转换成较白的颜色后有种过曝的效果：

![001](https://github.com/XyK0907/SemanticSegmentation/blob/master/changed_skin_001.jpg?raw=true)
![002](https://github.com/XyK0907/SemanticSegmentation/blob/master/changed_skin_002.jpg?raw=true)
![003](https://github.com/XyK0907/SemanticSegmentation/blob/master/changed_skin_003.jpg?raw=true)
![004](https://github.com/XyK0907/SemanticSegmentation/blob/master/changed_skin_004.jpg?raw=true)
![005](https://github.com/XyK0907/SemanticSegmentation/blob/master/changed_skin_005.jpg?raw=true)
![006](https://github.com/XyK0907/SemanticSegmentation/blob/master/changed_skin_006.jpg?raw=true)

若是以下小姐姐的肤色作为源肤色，

![000](https://github.com/XyK0907/SemanticSegmentation/blob/master/000.jpg?raw=true)

则转换后的图片如下所示：从第二张图片可以看出，仍有皮肤的边缘没有被识别和分割出来，导致颜色转换后能看出明显的分界线。后三张效果明显更好。
![001](https://github.com/XyK0907/SemanticSegmentation/blob/master/b_skin_001.jpg?raw=true)
![002](https://github.com/XyK0907/SemanticSegmentation/blob/master/b_skin_002.jpg?raw=true)
![003](https://github.com/XyK0907/SemanticSegmentation/blob/master/b_skin_003.jpg?raw=true)
![004](https://github.com/XyK0907/SemanticSegmentation/blob/master/b_skin_004.jpg?raw=true)
![005](https://github.com/XyK0907/SemanticSegmentation/blob/master/b_skin_005.jpg?raw=true)
![006](https://github.com/XyK0907/SemanticSegmentation/blob/master/b_skin_006.jpg?raw=true)

## Thinking
首先skin segmentation的训练集可以增大，这样使用训练出来的网络应该能够分割皮肤更精确。
其次，我使用的颜色迁移算法迁移后的图像有些并不自然，这种颜色的迁移更像是一个整体上颜色的叠加，没有考虑到光影关系等其它因素，会显得不太自然。应该寻找一种能考虑到当前肤色分布的颜色迁移算法。

## Reference
[Semantic Segmentation(Github)](https://github.com/WillBrennan/SemanticSegmentation)

## How to test?
The code is modified based on [Semantic Segmentation(Github)](https://github.com/WillBrennan/SemanticSegmentation). For the basic usage and installation details, please refer to it.

### Installation
```bash
conda env create -f enviroment.yml
conda activate semantic_segmentation
```

### Pre-trained Segmentation
This project comes bundled with several pretrained models, which can be found in the `pretrained` directory. To infer segmentation masks on your images run `evaluate_images`. 
```bash
# to display the output
python evaluate_images.py --images skin_tone_val/ --model pretrained/model_segmentation_skin_30.pth --ref_avg_a 30 --ref_avg_b 130 ----ref_avg_c 130 --ref_std_a 33 --ref_std_b 5 --ref_std_c 3 --model-type FCNResNet101 --display
# to save the output
python evaluate_images.py --images skin_tone_val --model pretrained/model_segmentation_skin_30.pth --ref_avg_a 30 --ref_avg_b 130 ----ref_avg_c 130 --ref_std_a 33 --ref_std_b 5 --ref_std_c 3 --model-type FCNResNet101 --save
```






```python

```
